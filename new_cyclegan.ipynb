{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from numpy import load\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy import asarray\n",
    "from numpy.random import randint\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms.functional as TF\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "\n",
    "from numpy import vstack\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from qartezator.data.dataset import QartezatorDataset\n",
    "from qartezator.data.datamodule import QartezatorDataModule\n",
    "from qartezator.data.transforms import get_common_augmentations\n",
    "from qartezator.data.datautils import load_image, pad_img_to_modulo\n",
    "import os\n",
    "import torch.nn.init as init\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def define_discriminator(image_shape):\n",
    "    # Weight initialization\n",
    "    def weights_init_uniform(m):\n",
    "        classname = m.__class__.__name__\n",
    "        if hasattr(m, 'weight') and (classname.find('Conv') != -1 or classname.find('Linear') != -1):\n",
    "            init.xavier_uniform_(m.weight.data)\n",
    "            if m.bias is not None:\n",
    "                init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "\n",
    "    # Define the discriminator network\n",
    "    model = nn.Sequential(\n",
    "        # C64: 4x4 kernel Stride 2x2\n",
    "        nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "        # C128: 4x4 kernel Stride 2x2\n",
    "        nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
    "        nn.InstanceNorm2d(128),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "        # C256: 4x4 kernel Stride 2x2\n",
    "        nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n",
    "        nn.InstanceNorm2d(256),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "        # C512: 4x4 kernel Stride 2x2\n",
    "        nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1),\n",
    "        nn.InstanceNorm2d(512),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "        # Second last output layer: 4x4 kernel Stride 1x1\n",
    "        nn.Conv2d(512, 512, kernel_size=4, stride=1, padding=1),\n",
    "        nn.InstanceNorm2d(512),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "        # Patch output\n",
    "        nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=1)\n",
    "    )\n",
    "\n",
    "    # Initialize the weights\n",
    "    model.apply(weights_init_uniform)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def resnet_block(n_filters, input_layer):\n",
    "    # Weight initialization\n",
    "    def weights_init_normal(m):\n",
    "        classname = m.__class__.__name__\n",
    "        if classname.find(\"Conv\") != -1:\n",
    "            nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "        elif classname.find(\"InstanceNorm2d\") != -1:\n",
    "            nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "            nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "    # Define the residual block\n",
    "    model = nn.Sequential(\n",
    "        # First convolutional layer\n",
    "        nn.Conv2d(n_filters, n_filters, kernel_size=3, stride=1, padding=1),\n",
    "        nn.InstanceNorm2d(n_filters),\n",
    "        nn.ReLU(inplace=True),\n",
    "        # Second convolutional layer\n",
    "        nn.Conv2d(n_filters, n_filters, kernel_size=3, stride=1, padding=1),\n",
    "        nn.InstanceNorm2d(n_filters)\n",
    "    )\n",
    "\n",
    "    # Initialize the weights\n",
    "    model.apply(weights_init_normal)\n",
    "\n",
    "    # Concatenate merge channel-wise with input layer\n",
    "    return nn.ReLU(inplace=True)(torch.cat([model(input_layer), input_layer], dim=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def define_generator(image_shape, n_resnet=6):\n",
    "    # Weight initialization\n",
    "    def weights_init_normal(m):\n",
    "        classname = m.__class__.__name__\n",
    "        if hasattr(m, 'weight') and (classname.find('Conv') != -1 or classname.find('Linear') != -1):\n",
    "            init.xavier_uniform_(m.weight.data)\n",
    "            if m.bias is not None:\n",
    "                init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "\n",
    "    # Define the residual block\n",
    "    class ResidualBlock(nn.Module):\n",
    "        def __init__(self, n_filters):\n",
    "            super(ResidualBlock, self).__init__()\n",
    "\n",
    "            self.conv1 = nn.Conv2d(n_filters, n_filters, kernel_size=3, stride=1, padding=1)\n",
    "            self.norm1 = nn.InstanceNorm2d(n_filters)\n",
    "            self.conv2 = nn.Conv2d(n_filters, n_filters, kernel_size=3, stride=1, padding=1)\n",
    "            self.norm2 = nn.InstanceNorm2d(n_filters)\n",
    "\n",
    "        def forward(self, x):\n",
    "            residual = x\n",
    "\n",
    "            out = F.relu(self.norm1(self.conv1(x)))\n",
    "            out = self.norm2(self.conv2(out))\n",
    "\n",
    "            out = out + residual\n",
    "\n",
    "            return out\n",
    "\n",
    "    # Define the generator network\n",
    "    class Generator(nn.Module):\n",
    "        def __init__(self, image_shape, n_resnet):\n",
    "            super(Generator, self).__init__()\n",
    "\n",
    "            self.c7s1_64 = nn.Sequential(\n",
    "                nn.ReflectionPad2d(3),\n",
    "                nn.Conv2d(3, 64, kernel_size=7, stride=1, padding=0),\n",
    "                nn.InstanceNorm2d(64),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "\n",
    "            self.d128 = nn.Sequential(\n",
    "                nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "                nn.InstanceNorm2d(128),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "\n",
    "            self.d256 = nn.Sequential(\n",
    "                nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),\n",
    "                nn.InstanceNorm2d(256),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "\n",
    "            self.resnet_blocks = nn.ModuleList([ResidualBlock(256) for _ in range(n_resnet)])\n",
    "\n",
    "            self.u128 = nn.Sequential(\n",
    "                nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "                nn.InstanceNorm2d(128),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "\n",
    "            self.u64 = nn.Sequential(\n",
    "                nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "                nn.InstanceNorm2d(64),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "\n",
    "            self.c7s1_3 = nn.Sequential(\n",
    "                nn.ReflectionPad2d(3),\n",
    "                nn.Conv2d(64, 3, kernel_size=7, stride=1, padding=0),\n",
    "                nn.InstanceNorm2d(3),\n",
    "                nn.Tanh()\n",
    "            )\n",
    "\n",
    "        def forward(self, x):\n",
    "            out = self.c7s1_64(x)\n",
    "            out = self.d128(out)\n",
    "            out = self.d256(out)\n",
    "\n",
    "            for resnet_block in self.resnet_blocks:\n",
    "                out = resnet_block(out)\n",
    "\n",
    "            out = self.u128(out)\n",
    "            out = self.u64(out)\n",
    "            out = self.c7s1_3(out)\n",
    "\n",
    "            return out\n",
    "\n",
    "    # Create an instance of the generator\n",
    "    generator = Generator(image_shape, n_resnet)\n",
    "\n",
    "    # Initialize the weights\n",
    "    generator.apply(weights_init_normal)\n",
    "\n",
    "    return generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def define_composite_model(g_model_1, d_model, g_model_2, image_shape):\n",
    "    # Make the generator of interest trainable as we will be updating these weights.\n",
    "    # by keeping other models constant.\n",
    "    # Remember that we use this same function to train both generators,\n",
    "    # one generator at a time.\n",
    "    g_model_1.trainable = True\n",
    "    # mark discriminator and second generator as non-trainable\n",
    "    d_model.trainable = False\n",
    "    g_model_2.trainable = False\n",
    "\n",
    "    # Define the composite model\n",
    "    class CompositeModel(nn.Module):\n",
    "        def __init__(self, g_model_1, d_model, g_model_2):\n",
    "            super(CompositeModel, self).__init__()\n",
    "\n",
    "            self.g_model_1 = g_model_1\n",
    "            self.d_model = d_model\n",
    "            self.g_model_2 = g_model_2\n",
    "\n",
    "        def forward(self, input_gen, input_id):\n",
    "            gen1_out = self.g_model_1(input_gen)\n",
    "            output_d = self.d_model(gen1_out)\n",
    "\n",
    "            output_id = self.g_model_1(input_id)\n",
    "\n",
    "            output_f = self.g_model_2(gen1_out)\n",
    "\n",
    "            gen2_out = self.g_model_2(input_id)\n",
    "            output_b = self.g_model_1(gen2_out)\n",
    "\n",
    "            return output_d, output_id, output_f, output_b\n",
    "\n",
    "    # Create an instance of the composite model\n",
    "    composite_model = CompositeModel(g_model_1, d_model, g_model_2)\n",
    "\n",
    "    # Define the optimizer\n",
    "    opt = optim.Adam(composite_model.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
    "\n",
    "    return composite_model, opt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_real_samples(dataset, n_samples, patch_shape):\n",
    "    # Choose random instances\n",
    "    ix = torch.randint(0, dataset.shape[0], (n_samples,))\n",
    "    # Retrieve selected images\n",
    "    X = dataset[ix]\n",
    "    # Generate 'real' class labels (1)\n",
    "    y = torch.ones((n_samples, 1, patch_shape, patch_shape))\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fake_samples(g_model, dataset, patch_shape):\n",
    "    # Set the generator model to evaluation mode\n",
    "    g_model.eval()\n",
    "\n",
    "    # Convert the dataset to a PyTorch tensor\n",
    "    dataset_tensor = torch.from_numpy(dataset).float()\n",
    "\n",
    "    # Generate fake images\n",
    "    with torch.no_grad():\n",
    "        X = g_model(dataset_tensor)\n",
    "\n",
    "    # Create 'fake' class labels (0)\n",
    "    batch_size = len(X)\n",
    "    y = torch.zeros(batch_size, 1, patch_shape, patch_shape)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_models(step, g_model_AtoB, g_model_BtoA):\n",
    "    # Save the first generator model\n",
    "    filename1 = 'g_model_AtoB_%06d.pth' % (step+1)\n",
    "    torch.save(g_model_AtoB.state_dict(), filename1)\n",
    "    # Save the second generator model\n",
    "    filename2 = 'g_model_BtoA_%06d.pth' % (step+1)\n",
    "    torch.save(g_model_BtoA.state_dict(), filename2)\n",
    "    print('> Saved: %s and %s' % (filename1, filename2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def summarize_performance(step, g_model, trainX, name, n_samples=5):\n",
    "    # Select a sample of input images\n",
    "    X_in, _ = generate_real_samples(trainX, n_samples, 0)\n",
    "    # Generate translated images\n",
    "    X_out, _ = generate_fake_samples(g_model, X_in, 0)\n",
    "    # Scale all pixels from [-1,1] to [0,1]\n",
    "    X_in = (X_in + 1) / 2.0\n",
    "    X_out = (X_out + 1) / 2.0\n",
    "\n",
    "    # Convert tensors to numpy arrays\n",
    "    X_in = X_in.permute(0, 2, 3, 1).numpy()\n",
    "    X_out = X_out.permute(0, 2, 3, 1).numpy()\n",
    "\n",
    "    # Plot real images\n",
    "    fig, axes = plt.subplots(2, n_samples, figsize=(10, 4))\n",
    "    for i in range(n_samples):\n",
    "        axes[0, i].axis('off')\n",
    "        axes[0, i].imshow(X_in[i])\n",
    "\n",
    "    # Plot translated images\n",
    "    for i in range(n_samples):\n",
    "        axes[1, i].axis('off')\n",
    "        axes[1, i].imshow(X_out[i])\n",
    "\n",
    "    # Save plot to file\n",
    "    filename1 = '%s_generated_plot_%06d.png' % (name, (step+1))\n",
    "    plt.savefig(filename1)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_image_pool(pool, images, max_size=50):\n",
    "    selected = []\n",
    "    for image in images:\n",
    "        if len(pool) < max_size:\n",
    "            # Stock the pool\n",
    "            pool.append(image)\n",
    "            selected.append(image)\n",
    "        elif random.random() < 0.5:\n",
    "            # Use image, but don't add it to the pool\n",
    "            selected.append(image)\n",
    "        else:\n",
    "            # Replace an existing image and use replaced image\n",
    "            ix = random.randint(0, len(pool) - 1)\n",
    "            selected.append(pool[ix])\n",
    "            pool[ix] = image\n",
    "    return np.asarray(selected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train(d_model_A, d_model_B, g_model_AtoB, g_model_BtoA, c_model_AtoB, c_model_BtoA, train_dataloader, epochs=1):\n",
    "    # Define properties of the training run\n",
    "    n_epochs= epochs\n",
    "    n_batch=32\n",
    "    # Determine the output square shape of the discriminator\n",
    "    n_patch = 14\n",
    "    #input_shape = dataset[0][0].shape\n",
    "    #dummy_input = torch.rand(n_batch, *input_shape)\n",
    "    #n_patch = d_model_A(dummy_input).shape[2]\n",
    "    # Unpack dataset\n",
    "    #trainA, trainB = train_data\n",
    "    # Prepare image pool for fake images\n",
    "    poolA, poolB = [], []\n",
    "    # Calculate the number of batches per training epoch\n",
    "    #bat_per_epo = len(trainA) // n_batch\n",
    "    # Calculate the number of training iterations\n",
    "    #n_steps = bat_per_epo * n_epochs\n",
    "\n",
    "    # Define loss functions\n",
    "    adversarial_loss = nn.MSELoss()\n",
    "    identity_loss = nn.L1Loss()\n",
    "    cycle_loss = nn.L1Loss()\n",
    "\n",
    "    # Define optimizers\n",
    "    optimizer_c_AtoB = optim.Adam(c_model_AtoB.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
    "    optimizer_c_BtoA = optim.Adam(c_model_BtoA.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
    "    optimizer_d_A = optim.Adam(d_model_A.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
    "    optimizer_d_B = optim.Adam(d_model_B.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
    "    optimizer_g_AtoB = optim.Adam(g_model_AtoB.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
    "    optimizer_g_BtoA = optim.Adam(g_model_BtoA.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
    "\n",
    "    # Create data loaders\n",
    "    #dataloader_A = DataLoader(trainA, batch_size=n_batch, shuffle=True)\n",
    "    #dataloader_B = DataLoader(trainB, batch_size=n_batch, shuffle=True)\n",
    "\n",
    "    # Manually enumerate epochs\n",
    "    for epoch in range(n_epochs):\n",
    "        # Enumerate over the data loaders\n",
    "        for i, (real_B,real_A) in enumerate(train_dataloader):\n",
    "            # Move real images to the device\n",
    "            real_A=(real_A-0.5)/0.5\n",
    "            real_B=(real_B-0.5)/0.5\n",
    "            real_A = real_A.to(device)\n",
    "            real_B = real_B.to(device)\n",
    "            \n",
    "\n",
    "            ##############################\n",
    "            # Update AtoB Generator\n",
    "            ##############################\n",
    "\n",
    "            # Set generators' gradients to zero\n",
    "            optimizer_g_AtoB.zero_grad()\n",
    "            optimizer_c_AtoB.zero_grad()\n",
    "\n",
    "            # Generate fake images\n",
    "            fake_B = g_model_AtoB(real_A)\n",
    "            fake_A = g_model_BtoA(real_B)\n",
    "            \n",
    "            # Update image pool for fake images\n",
    "            fake_A = update_image_pool(poolA, fake_A.detach().cpu().numpy())\n",
    "            fake_B = update_image_pool(poolB, fake_B.detach().cpu().numpy())\n",
    "            fake_A_tensor = torch.from_numpy(fake_A).to(device)\n",
    "            fake_B_tensor = torch.from_numpy(fake_B).to(device)\n",
    "\n",
    "            # Adversarial loss\n",
    "            \n",
    "            pred_fake_A = d_model_A(fake_A_tensor)\n",
    "            pred_fake_B = d_model_B(fake_B_tensor)\n",
    "            loss_adv_AtoB = adversarial_loss(pred_fake_A, torch.ones_like(pred_fake_A))\n",
    "            loss_adv_BtoA = adversarial_loss(pred_fake_B, torch.ones_like(pred_fake_B))\n",
    "\n",
    "            # Identity loss\n",
    "            idt_A = g_model_BtoA(real_A)\n",
    "            idt_B = g_model_AtoB(real_B)\n",
    "            loss_idt_A = identity_loss(idt_A, real_A)\n",
    "            loss_idt_B = identity_loss(idt_B, real_B)\n",
    "\n",
    "            # Cycle-consistency loss\n",
    "            \n",
    "            cycle_A = g_model_BtoA(fake_B_tensor)\n",
    "            cycle_B = g_model_AtoB(fake_A_tensor)\n",
    "            loss_cycle_A = cycle_loss(cycle_A, real_A)\n",
    "            loss_cycle_B = cycle_loss(cycle_B, real_B)\n",
    "\n",
    "            # Total loss\n",
    "            loss_g_AtoB = loss_adv_AtoB + 5 * loss_idt_A + 10 * loss_cycle_A\n",
    "            loss_g_BtoA = loss_adv_BtoA + 5 * loss_idt_B + 10 * loss_cycle_B\n",
    "\n",
    "            # Backpropagation and optimization\n",
    "            loss_g_AtoB.backward()\n",
    "            optimizer_g_AtoB.step()\n",
    "            optimizer_c_AtoB.step()\n",
    "\n",
    "            ##############################\n",
    "            # Update BtoA Generator\n",
    "            ##############################\n",
    "\n",
    "            # Set generators' gradients to zero\n",
    "            optimizer_g_BtoA.zero_grad()\n",
    "            optimizer_c_BtoA.zero_grad()\n",
    "\n",
    "            # Generate fake images\n",
    "            fake_A = g_model_BtoA(real_B)\n",
    "            fake_B = g_model_AtoB(real_A)\n",
    "\n",
    "            # Update image pool for fake images\n",
    "            fake_B = update_image_pool(poolB, fake_B.detach().cpu().numpy())\n",
    "            fake_A = update_image_pool(poolA, fake_A.detach().cpu().numpy())\n",
    "            fake_A_tensor = torch.from_numpy(fake_A).to(device)\n",
    "            fake_B_tensor = torch.from_numpy(fake_B).to(device)\n",
    "\n",
    "            # Adversarial loss\n",
    "            #fake_A_tensor = torch.from_numpy(fake_A)\n",
    "            #fake_B_tensor = torch.from_numpy(fake_B)\n",
    "            pred_fake_B = d_model_B(fake_B_tensor)\n",
    "            pred_fake_A = d_model_A(fake_A_tensor)\n",
    "            loss_adv_BtoA = adversarial_loss(pred_fake_B, torch.ones_like(pred_fake_B))\n",
    "            loss_adv_AtoB = adversarial_loss(pred_fake_A, torch.ones_like(pred_fake_A))\n",
    "\n",
    "            # Identity loss\n",
    "            idt_B = g_model_AtoB(real_B)\n",
    "            idt_A = g_model_BtoA(real_A)\n",
    "            loss_idt_B = identity_loss(idt_B, real_B)\n",
    "            loss_idt_A = identity_loss(idt_A, real_A)\n",
    "\n",
    "            # Cycle-consistency loss\n",
    "            cycle_B = g_model_AtoB(fake_A_tensor)\n",
    "            cycle_A = g_model_BtoA(fake_B_tensor)\n",
    "            loss_cycle_B = cycle_loss(cycle_B, real_B)\n",
    "            loss_cycle_A = cycle_loss(cycle_A, real_A)\n",
    "\n",
    "            # Total loss\n",
    "            loss_g_BtoA = loss_adv_BtoA + 5 * loss_idt_B + 10 * loss_cycle_B\n",
    "            loss_g_AtoB = loss_adv_AtoB + 5 * loss_idt_A + 10 * loss_cycle_A\n",
    "\n",
    "            # Backpropagation and optimization\n",
    "            loss_g_BtoA.backward()\n",
    "            optimizer_g_BtoA.step()\n",
    "            optimizer_c_BtoA.step()\n",
    "\n",
    "            ##############################\n",
    "            # Update Discriminators\n",
    "            ##############################\n",
    "\n",
    "            # Set discriminators' gradients to zero\n",
    "            optimizer_d_A.zero_grad()\n",
    "            optimizer_d_B.zero_grad()\n",
    "\n",
    "            # Real loss\n",
    "            pred_real_A = d_model_A(real_A)\n",
    "            pred_real_B = d_model_B(real_B)\n",
    "            loss_real_A = adversarial_loss(pred_real_A, torch.ones_like(pred_real_A))\n",
    "            loss_real_B = adversarial_loss(pred_real_B, torch.ones_like(pred_real_B))\n",
    "\n",
    "            # Fake loss\n",
    "            pred_fake_A = d_model_A(fake_A_tensor.detach())\n",
    "            pred_fake_B = d_model_B(fake_B_tensor.detach())\n",
    "            loss_fake_A = adversarial_loss(pred_fake_A, torch.zeros_like(pred_fake_A))\n",
    "            loss_fake_B = adversarial_loss(pred_fake_B, torch.zeros_like(pred_fake_B))\n",
    "\n",
    "            # Total loss\n",
    "            loss_d_A = (loss_real_A + loss_fake_A) * 0.5\n",
    "            loss_d_B = (loss_real_B + loss_fake_B) * 0.5\n",
    "\n",
    "            # Backpropagation and optimization\n",
    "            loss_d_A.backward()\n",
    "            optimizer_d_A.step()\n",
    "\n",
    "            loss_d_B.backward()\n",
    "            optimizer_d_B.step()\n",
    "\n",
    "            ##############################\n",
    "            # Summarize Performance\n",
    "            ##############################\n",
    "            #if (i + 1) % (bat_per_epo * 5) == 0:\n",
    "                # Save the models\n",
    "                #save_models(i, g_model_AtoB, g_model_BtoA)\n",
    "\n",
    "            \n",
    "        print(f\"Epoch [{epoch+1}/{n_epochs}] | Generator Loss: {loss_g_BtoA} | Discriminator Loss: {loss_g_AtoB}\")\n",
    "                # Plot A->B translation\n",
    "                #trainA_tensor = torch.from_numpy(trainA.numpy())\n",
    "                #trainB_tensor = torch.from_numpy(trainB.numpy())\n",
    "                # Plot A->B translation\n",
    "                #summarize_performance(i, g_model_AtoB, trainA_tensor.permute(1, 3, 256, 256), 'AtoB')\n",
    "    \n",
    "    # Plot B->A translation\n",
    "                #summarize_performance(i, g_model_BtoA, trainB_tensor.permute(1, 3, 256, 256), 'BtoA')\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = './data/maps'\n",
    "train_txt_path = './assets/train.txt'\n",
    "val_txt_path = './assets/val.txt'\n",
    "test_txt_path = './assets/test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_directory = r'C:\\Users\\User\\Desktop\\qartezator'\n",
    "os.chdir(new_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = QartezatorDataset(\n",
    "    root_path=root_path,\n",
    "    split_file_path=train_txt_path,\n",
    "    common_transform=get_common_augmentations(256)\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = QartezatorDataset(\n",
    "    root_path=root_path,\n",
    "    split_file_path=test_txt_path,\n",
    "    common_transform=get_common_augmentations(256)\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = QartezatorDataModule(\n",
    "    root_path=root_path,\n",
    "    train_txt_path=train_txt_path,\n",
    "    val_txt_path=val_txt_path,\n",
    "    test_txt_path=test_txt_path,\n",
    "    input_size=256\n",
    ")\n",
    "train_dataloader = dm.train_dataloader()\n",
    "val_dataloader = dm.val_dataloader()\n",
    "test_dataloader = dm.test_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source batch shape: torch.Size([32, 3, 256, 256])\n",
      "Target batch shape: torch.Size([32, 3, 256, 256])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    source, target = batch\n",
    "    print(f'Source batch shape: {source.shape}')\n",
    "    print(f'Target batch shape: {target.shape}\\n')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source batch shape: torch.Size([32, 3, 608, 608])\n",
      "Target batch shape: torch.Size([32, 3, 608, 608])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for batch in test_dataloader:\n",
    "    source_t, target_t = batch\n",
    "    print(f'Source batch shape: {source_t.shape}')\n",
    "    print(f'Target batch shape: {target_t.shape}\\n')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = source.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 256, 256])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_model_AtoB = define_generator(image_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator: B -> A\n",
    "g_model_BtoA = define_generator(image_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discriminator: A -> [real/fake]\n",
    "d_model_A = define_discriminator(image_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discriminator: B -> [real/fake]\n",
    "d_model_B = define_discriminator(image_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# composite: A -> B -> [real/fake, A]\n",
    "c_model_AtoB, optimizer_c_AtoB  = define_composite_model(g_model_AtoB, d_model_B, g_model_BtoA, image_shape)\n",
    "# composite: B -> A -> [real/fake, B]\n",
    "c_model_BtoA,optimizer_c_BtoA = define_composite_model(g_model_BtoA, d_model_A, g_model_AtoB, image_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime \n",
    "start1 = datetime.now() \n",
    "# train models\n",
    "train(d_model_A, d_model_B, g_model_AtoB, g_model_BtoA, c_model_AtoB, c_model_BtoA, train_dataloader, epochs=5)\n",
    "\n",
    "stop1 = datetime.now()\n",
    "#Execution time of the model \n",
    "execution_time = stop1-start1\n",
    "print(\"Execution time is: \", execution_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My Environment",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
